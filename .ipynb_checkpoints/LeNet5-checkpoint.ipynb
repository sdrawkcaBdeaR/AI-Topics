{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zT52si9uBMcd"
   },
   "source": [
    "#### AI61002_Spr2023\n",
    "#### Tutorial 1: Training LeNet for for MNIST Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "1JyAhPUwg5_r"
   },
   "outputs": [],
   "source": [
    "# import libaries\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torchvision import transforms,datasets\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_T3rJUPDBMcq"
   },
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jQOmc53jhLzr"
   },
   "outputs": [],
   "source": [
    "apply_transform = transforms.Compose([transforms.Resize(32), transforms.ToTensor()])\n",
    "BatchSize = 256 # change according to system specs\n",
    "\n",
    "\n",
    "\n",
    "trainset = datasets.MNIST(root='./MNIST', train=True, download=True, transform=apply_transform)\n",
    "trainLoader = torch.utils.data.DataLoader(trainset, batch_size=BatchSize,\n",
    "                                          shuffle=True, num_workers=1) # Creating dataloader\n",
    "\n",
    "\n",
    "testset = datasets.MNIST(root='./MNIST', train=False, download=True, transform=apply_transform)\n",
    "testLoader = torch.utils.data.DataLoader(testset, batch_size=BatchSize,\n",
    "                                         shuffle=False, num_workers=1) # Creating dataloader\n",
    "                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vfft59iCkHXQ"
   },
   "outputs": [],
   "source": [
    "# Size of train and test datasets\n",
    "print('No. of samples in train set: '+str(len(trainLoader.dataset)))\n",
    "print('No. of samples in test set: '+str(len(testLoader.dataset)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rvMjk-O7Fpxh"
   },
   "outputs": [],
   "source": [
    "image, label2 = trainset[0]\n",
    "image.shape, label2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ss3UNAZpFtSM"
   },
   "outputs": [],
   "source": [
    "def show_img(img, label):\n",
    "    print('Label: ', label)\n",
    "    plt.imshow(torch.squeeze(img), cmap = 'gray')\n",
    "show_img(*trainset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2gshNzmvBMcy"
   },
   "source": [
    "#### Define model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ykZ_LOB8kOTY"
   },
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2,stride=2)        \n",
    "        self.fc1 = nn.Linear(400, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.logSoftmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool2(x)\n",
    "        x = x.view(-1, 400)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x) \n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return self.logSoftmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WeVHHMKxBMc3"
   },
   "outputs": [],
   "source": [
    "net= LeNet()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yHpE7v5LBMdA"
   },
   "outputs": [],
   "source": [
    "# Define same network for shape print\n",
    "class LeNet1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet1, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2,stride=2)        \n",
    "        self.fc1 = nn.Linear(400, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.logSoftmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(\"Shape of input:\", x.shape)\n",
    "        x = self.conv1(x)\n",
    "        print(\"Shape after 1st Conv:\", x.shape)\n",
    "        x = self.relu(x)\n",
    "        print(\"Shape after 1st ReLu:\", x.shape)\n",
    "        x = self.pool1(x)\n",
    "        print(\"Shape after 1st MaxPool:\", x.shape)\n",
    "        x = self.conv2(x)\n",
    "        print(\"Shape after 2nd Conv:\", x.shape)\n",
    "        x = self.relu(x)\n",
    "        print(\"Shape after 2nd Relu:\", x.shape)\n",
    "        x = self.pool2(x)\n",
    "        print(\"Shape after 2nd MaxPool:\", x.shape)\n",
    "        x = x.view(-1, 400)\n",
    "        print(\"Shape before 1st FC:\", x.shape)\n",
    "        x = self.fc1(x)\n",
    "        print(\"Shape after 1st FC:\", x.shape)\n",
    "        x = self.relu(x)\n",
    "        print(\"Shape after 3rd ReLu:\", x.shape)\n",
    "        x = self.fc2(x)\n",
    "        print(\"Shape after 2nd FC:\", x.shape)\n",
    "        x = self.relu(x)\n",
    "        print(\"Shape after 4th ReLu:\", x.shape)\n",
    "        x = self.fc3(x)\n",
    "        print(\"Shape after 3rd FC:\", x.shape)\n",
    "        return self.logSoftmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xx2bLAlwBMdC"
   },
   "outputs": [],
   "source": [
    "net1= LeNet1()\n",
    "#print(net1)\n",
    "image = image.reshape(1,1,32,32)# To maintain the input shape of the network\n",
    "net1(image)\n",
    "#torch.argmax(net1(image),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2qriKm7GBMdE"
   },
   "outputs": [],
   "source": [
    "# Check availability of GPU\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    print('GPU is available!')\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    print('GPU is not available!')\n",
    "    device = \"cpu\"\n",
    "\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TKvgsDpAkpgr"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss() \n",
    "learning_rate = 0.01\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate) # ADAM \n",
    "num_epochs = 20\n",
    "\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    running_loss = 0.0 \n",
    "    running_corr = 0\n",
    "        \n",
    "    for i,data in enumerate(trainLoader):\n",
    "        inputs,labels = data\n",
    "        if use_gpu:\n",
    "            inputs, labels = inputs.to(device),labels.to(device)\n",
    "        # Initializing model gradients to zero\n",
    "        \n",
    "        optimizer.zero_grad() \n",
    "        # Data feed-forward through the network\n",
    "        outputs1 = net(inputs)\n",
    "        # Predicted class is the one with maximum probability\n",
    "        preds1 = torch.argmax(outputs1,dim=1)\n",
    "        # Finding the loss\n",
    "        loss = criterion(outputs1, labels)\n",
    "        # Accumulating the loss for each batch\n",
    "        running_loss += loss \n",
    "        # Accumulate number of correct predictions\n",
    "        running_corr += torch.sum(preds1==labels)    \n",
    "        \n",
    "    totalLoss1 = running_loss/(i+1)\n",
    "    # Calculating gradients\n",
    "    totalLoss1.backward()\n",
    "    # Updating the model parameters\n",
    "    optimizer.step()\n",
    "        \n",
    "    epoch_loss = running_loss.item()/(i+1)   #Total loss for one epoch\n",
    "    epoch_acc = running_corr.item()/60000\n",
    "    \n",
    "    \n",
    "         \n",
    "    train_loss.append(epoch_loss) #Saving the loss over epochs for plotting the graph\n",
    "    train_acc.append(epoch_acc) #Saving the accuracy over epochs for plotting the graph\n",
    "       \n",
    "        \n",
    "    print('Epoch {:.0f}/{:.0f} : Training loss: {:.4f} | Training Accuracy: {:.4f}'.format(epoch+1,num_epochs,epoch_loss,epoch_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GiS_V5PIBMdI"
   },
   "outputs": [],
   "source": [
    "torch.argmax(net(image.to(device)),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KJV5K495Hn-o"
   },
   "outputs": [],
   "source": [
    "# Plot the curves of tranning loss and training accuracy\n",
    "fig = plt.figure(figsize=[15,5]) \n",
    "plt.subplot(121)\n",
    "plt.plot(range(num_epochs),train_loss,'r-',label='Loss/error') \n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Training')\n",
    "plt.subplot(122)\n",
    "plt.plot(range(num_epochs),train_acc,'g-',label='Accuracy') \n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zGR6qS5sBMdM"
   },
   "source": [
    "#### Evaluation of trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rxs1v0BcNa7e"
   },
   "outputs": [],
   "source": [
    "correct_pred=0\n",
    "for data in testLoader:\n",
    "    inputs,labels = data\n",
    "    if use_gpu:\n",
    "        inputs, labels = inputs.to(device),labels.to(device)\n",
    "    # Feedforward test data batch through model\n",
    "    output = net(inputs) \n",
    "    # Predicted class is the one with maximum probability\n",
    "    preds1 = torch.argmax(output,dim=1)\n",
    "    correct_pred += torch.sum(preds1==labels)\n",
    "\n",
    "test_accuracy = correct_pred.item()/10000.0\n",
    "print('Testing accuracy = ',test_accuracy*100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "52VNfHck9HHd"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "private_outputs": true,
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "1bc3bbbe5f53ad25d170f74cc28082fcc8790e005df27e5bb68986976a08031e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
